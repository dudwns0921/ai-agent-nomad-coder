{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a030de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI()\n",
    "\n",
    "PROMPT = \"\"\"\n",
    "I have the following functions in my system.\n",
    "\n",
    "'get_weather'\n",
    "'get_currency'\n",
    "'get_news'\n",
    "\n",
    "All of them receive the name of a country as an argument (i.e. get_weather('Spain'))\n",
    "\n",
    "Please, answer with the name of the function that you would like me to run.\n",
    "\n",
    "Please, say nothing else, just the name of the function with the arguments.\n",
    "\n",
    "Answer the following question:\n",
    "\n",
    "What is the weather in Korea?\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": PROMPT},\n",
    "    ],\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46f8870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "clientForLoop = openai.OpenAI()\n",
    "messages = []\n",
    "\n",
    "def call_ai():\n",
    "    response = clientForLoop.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    message = response.choices[0].message.content\n",
    "    messages.append({\"role\": \"assistant\", \"content\": message})\n",
    "    print(\"AI:\", message)\n",
    "\n",
    "while True:\n",
    "    message = input(\"Send a message to the LLM...\")\n",
    "    if message == \"quit\":\n",
    "        break\n",
    "    else:\n",
    "        messages.append({\"role\": \"user\", \"content\": message})\n",
    "        print(\"User:\", message)\n",
    "        answer = call_ai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bf9085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: what is the weather of spain?\n",
      "Calling function get_weather with arguments {\"city\":\"Spain\"}\n",
      "Function response: The weather in Spain is 25 degrees Celsius with clear skies.\n",
      "AI: The weather in Spain is currently 25 degrees Celsius with clear skies.\n",
      "AI: ChatCompletionMessage(content='The weather in Spain is currently 25 degrees Celsius with clear skies.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n",
      "AI: ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_vc9t8L5cIAjcxfsmEF29nnet', function=Function(arguments='{\"city\":\"Spain\"}', name='get_weather'), type='function')])\n",
      "User: tell me what is the weather of spain?\n",
      "AI: The weather in Spain is currently 25 degrees Celsius with clear skies.\n",
      "AI: ChatCompletionMessage(content='The weather in Spain is currently 25 degrees Celsius with clear skies.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from openai.types.chat import ChatCompletionMessage\n",
    "import json\n",
    "\n",
    "def get_weather(city):\n",
    "    return f\"The weather in {city} is 25 degrees Celsius with clear skies.\"\n",
    "\n",
    "FUNCTION_MAP = {\n",
    "    'get_weather': get_weather,\n",
    "}\n",
    "\n",
    "TOOL = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get the weather in a country\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The name of city to get the weather for\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"city\"],\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "clientForTool = openai.OpenAI()\n",
    "messages = []\n",
    "\n",
    "def process_ai_response(message: ChatCompletionMessage):\n",
    "    if message.tool_calls is not None and len(message.tool_calls) > 0:\n",
    "        messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": message.content or \"\",\n",
    "            \"tool_calls\": [\n",
    "                {\n",
    "                    \"id\": tool_call.id,\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": tool_call.function.name,\n",
    "                        \"arguments\": tool_call.function.arguments,\n",
    "                    }\n",
    "                } for tool_call in message.tool_calls\n",
    "            ]\n",
    "        })\n",
    "\n",
    "        for tool_call in message.tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            arguments = tool_call.function.arguments\n",
    "\n",
    "            print(f\"Calling function {function_name} with arguments {arguments}\")\n",
    "\n",
    "            try:\n",
    "                arguments = json.loads(arguments)\n",
    "            except json.JSONDecodeError:\n",
    "                arguments = {}\n",
    "                print(\"Error decoding JSON arguments:\", arguments)\n",
    "            \n",
    "            function_to_call = FUNCTION_MAP[function_name]\n",
    "            function_response = function_to_call(**arguments)\n",
    "            messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            })\n",
    "            print(f\"Function response: {function_response}\")\n",
    "            call_ai_with_tool()\n",
    "    else:\n",
    "        messages.append({\"role\": \"assistant\", \"content\": message.content or \"\"})\n",
    "        print(\"AI:\", message.content or \"\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def call_ai_with_tool():\n",
    "    response = clientForTool.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        tools=TOOL,\n",
    "    )\n",
    "    message = response.choices[0].message\n",
    "    process_ai_response(message)\n",
    "\n",
    "\n",
    "while True:\n",
    "    message = input(\"Send a message to the LLM...\")\n",
    "    if message == \"quit\":\n",
    "        break\n",
    "    else:\n",
    "        messages.append({\"role\": \"user\", \"content\": message})\n",
    "        print(\"User:\", message)\n",
    "        answer = call_ai_with_tool()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "first-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
